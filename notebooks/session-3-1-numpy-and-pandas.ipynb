{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87d17582",
   "metadata": {},
   "source": [
    "# <div align='center'>Introduction to Python for data analysis: NumPy and pandas libraries</div>\n",
    "\n",
    "NumPy and pandas are two fundamental libraries for data analysis. They are used to efficiently manipulate and prepare data for analysis and visualization. These tools are used to clean the data and make operations.\n",
    "\n",
    "# Contents\n",
    "\n",
    "1. <a href=\"#numpy\">NumPy</a>\n",
    "    1. <a href='#ndarray'>Introduction to ndarray</a>\n",
    "    2. <a href='#print_array'>Printing arrays</a>\n",
    "    3. <a href='#create_array'>How to create a ndarray?</a>\n",
    "    4. <a href='#indexing'>Indexing, slicing and iterating</a>\n",
    "    5. <a href='#shaping'>Changing the shape of an array</a>\n",
    "    6. <a href='#concatenating'>Concatenating, joining and stacking arrays</a>\n",
    "    7. <a href='#adding'>Adding, sorting and removing elements</a>\n",
    "    8. <a href='#random'>Random number generation</a>\n",
    "3. <a href=\"#pandas\">Pandas</a>\n",
    "    1. <a href='#series'>Series</a>\n",
    "    2. <a href='#dataframes'>DataFrames</a>\n",
    "        1. <a href='#csv'>Create a DataFrame from a CSV file</a>\n",
    "        2. <a href='#dict'>Create a DataFrame from a dictionary</a>\n",
    "        3. <a href='#array'>Create a DataFrame from a NumPy array</a>\n",
    "        4. <a href=\"#summarize\">Summarize data</a>\n",
    "        5. <a href=\"#combine\">Combining and merging DataFrames</a>\n",
    "        6. <a href='#write'>Save DataFrames to a file and convert to NumPy array</a>\n",
    "        7. <a href=\"#clean\">Handling missing data</a>\n",
    "        8. <a href=\"#transform\">Transform and replace data</a>\n",
    "        9. <a href=\"#remove\">Remove unwanted rows/columns</a>\n",
    "        10. <a href=\"#query\">Examine the data and make selections and queries</a>\n",
    "        11. <a href=\"#add\">Add new columns/rows</a>\n",
    "        12. <a href=\"#plotting\">Plotting</a>\n",
    "        13. <a href=\"#other\">Other helpful attributes and functions</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7079f7da",
   "metadata": {},
   "source": [
    "## <div id=\"numpy\">1. NumPy</div>\n",
    "\n",
    "[NumPy](https://numpy.org/) is a powerful library that offers comprehensive mathematical functions, random number generators, linear algebra routines and much more. Its main data object is a multidimensional array, known as ```ndarray```, which is significantly faster than the Python built-in list data type. A Python list can contain different data types, while in a NumPy array, all elements should be homogeneous.\n",
    "\n",
    "**Why use NumPy over Python lists?**\n",
    "\n",
    "NumPy arrays are faster and consume less memory than Python lists."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45aa8de2",
   "metadata": {},
   "source": [
    "Let's import NumPy and introduce its most common and useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cef6c24",
   "metadata": {},
   "source": [
    "If the above didn't work, please run the following on a terminal/console:\n",
    "```\n",
    "pip install numpy\n",
    "```\n",
    "or\n",
    "```\n",
    "pip3 install numpy\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bc6aadc",
   "metadata": {},
   "source": [
    "### <div id=\"ndarray\">1.A Introduction to ndarray</div>\n",
    "\n",
    "A ```ndarray``` could be considered as a table containing elements of the same type, indexed by non-negative integers.\n",
    "These arrays are multidimensional and the dimensions of an ```ndarray``` object are called axes. A ```ndarray``` can be created with the ```np.array()``` function (not to be confused with the ```array.array``` arrays). Let's take a look at a couple of examples:\n",
    "\n",
    "<u>Example of a ndarray with a single axis:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1d = np.array([1, 2, 0])\n",
    "print(a1d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53e247e9",
   "metadata": {},
   "source": [
    "The above array has one axis and three elements (i.e. its lenght is 3)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2cc58dc",
   "metadata": {},
   "source": [
    "<u>Example of a ndarray with two axes:</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d = np.array([[1, 2, 0], [2, 0, 3]])\n",
    "print(a2d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77f2e23b",
   "metadata": {},
   "source": [
    "The ```a2d``` array has 2 axes, the first one has a lenght of 2 and the second one a lenght of 3.\n",
    "\n",
    "<u>Let's take a look a some useful methods:</u>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "467ce81a",
   "metadata": {},
   "source": [
    "1. ```ndarray.ndim```:\n",
    "\n",
    "    Returns the number of axes (i.e. dimensions) of an array. Let's confirm it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96656287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a1d.ndim = }')\n",
    "print(f'{a2d.ndim = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bf63ed9",
   "metadata": {},
   "source": [
    "2. ```ndarray.shape```:\n",
    "\n",
    "    Returns a tuple containing the lenght of each dimension. For a matrix with ```n``` rows and ```m``` columns, ```shape``` will be ```(n,m)```. The length of the tuple is hence the number of axes (i.e. it agrees with ```ndim```). Let's confirm it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56286df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a1d.shape = }')\n",
    "print(f'{a2d.shape = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4050d27",
   "metadata": {},
   "source": [
    "3. ```ndarray.size```:\n",
    "\n",
    "    Returns the total number of elements in the array. This is equal to the product of all the elements in the shape tuple. Let's confirm it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e39140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a1d.size = }')\n",
    "print(f'{a2d.size = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbd657a2",
   "metadata": {},
   "source": [
    "### <div id=\"create_array\">1.B How to create a ndarray?</div>\n",
    "\n",
    "There are a few different ways to create a NumPy array. The main function to create one is the ```arrray()``` function to which we can provide a list or a tuple. We saw a couple of examples already using a list. Let's see a couple of examples using a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e158d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array_1 = np.array((2, 3, 1))\n",
    "print(my_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978bd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array_2 = np.array(((2, 3, 1), (0, 1, 2)))\n",
    "print(my_array_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e2dc2ff",
   "metadata": {},
   "source": [
    "\n",
    "**Note:** The type of the array is deduced from the type of the provided elements.\n",
    "\n",
    "Sometimes, we know the shape and the size of the array that we need, but we don't necessarily have the elements yet. For such cases, we have a few different functions to create arrays with placeholder elements (this is recommended over increasing the size of an array which is an expensive operation). We will see only two of them:\n",
    "\n",
    "1. ```zeros(shape)```:\n",
    "\n",
    "It creates an array full of zeros using the provided shape. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0670b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "nzeros = np.zeros((2, 3))\n",
    "print(nzeros)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f5312f1",
   "metadata": {},
   "source": [
    "2. ```ones(shape)```:\n",
    "\n",
    "Similarly to the ```zeros()``` function, ```ones()``` creates an array full of ones using the provided shape. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee26fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nones = np.ones((2, 3))\n",
    "print(nones)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0710c26a",
   "metadata": {},
   "source": [
    "**Note:** By default, the type of the created array is ```float64```, but it can be specified via the keyword argument ```dtype``` (this is true for all the functions we have seen, i.e. ```array()```, ```zeros()``` and ```ones()```)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0004ed70",
   "metadata": {},
   "source": [
    "If we wish to create a sequence of numbers, we can use the ```arange()``` function which is analogous to the Python built-in range function but in this case it retuns a ndarray. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd293a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sequence = np.arange(1, 30)\n",
    "print(my_sequence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "229a8003",
   "metadata": {},
   "source": [
    "If we wish to create a sequence of float numbers, we can use the ```linspace()``` function. For example, the following will create an array of 11 numbers from 0 to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61b8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sequence_float = np.linspace(0, 1, 11)\n",
    "print(my_sequence_float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c81a66a",
   "metadata": {},
   "source": [
    "**Note:** We could have used the ```arange()``` function providing a third parameter (i.e. a float number as the step size) but sometimes it is not possible to predict the number of elements obtained, due to the finite floating point precision."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29991165",
   "metadata": {},
   "source": [
    "### <div id=\"print_array\">1.C Printing arrays</div>\n",
    "\n",
    "One-dimensional arrays are printed as rows, bidimensionals arrays as matrices and tridimensionals arrays as lists of matrices. Examples:\n",
    "\n",
    "1. 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1d = np.arange(10)\n",
    "print(f'{a1d = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d667841",
   "metadata": {},
   "source": [
    "2. 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d = np.array([[1, 2, 3], [2, 4, 5]])\n",
    "print(f'{a2d = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f0e3302",
   "metadata": {},
   "source": [
    "3. 3D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a3d = np.array([[[1, 2, 3], [2, 4, 5]], [[0, 2, 3], [1, 5, 8]]])\n",
    "print(f'{a3d = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e974994",
   "metadata": {},
   "source": [
    "**Note:** If an array is too large to be fully displayed, NumPy skips the central part of the array. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d56d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.arange(10000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7072a45b",
   "metadata": {},
   "source": [
    "### <div id=\"operations\">1.D Arithmetic operations</div>\n",
    "\n",
    "Arithmetic operations on arrays are applied element-wise and a new array is created and filled with the result of the operation. Let's create two arrays and then do some operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 3, 5, 6, 8, 9, 13, 15, 12, 24])\n",
    "b = np.arange(0, 10)\n",
    "print(f'{a = }')\n",
    "print(f'{b = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab64b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtraction\n",
    "c = a - b\n",
    "print(f'c = a - b = {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ecd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplication\n",
    "c = a*2\n",
    "print(f'c = a*2 = {c}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd20d13e",
   "metadata": {},
   "source": [
    "**Note:** If we wish to perform a matrix product, we need to use the ```@``` operator (available in Python>=3.5) or the ```dot()``` function. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e8dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_a = np.array([[0, 2], [1, 3]])\n",
    "matrix_b = np.array([[0, 1], [1, 0]])\n",
    "matrix_product = matrix_a @ matrix_b\n",
    "print(f'{matrix_product = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiation\n",
    "c = a**2\n",
    "print(f'c = a**2 = {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which elements in \"a\" are even\n",
    "c = a % 2 == 0\n",
    "print(f'c = (a % 2 == 0) = {c}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7c92129",
   "metadata": {},
   "source": [
    "**Note:** The ```+=``` and ```*=``` operations modify an existing array instead of creating a new one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6e3c57",
   "metadata": {},
   "source": [
    "Let's take a look at some helpful NumPy built-in mathematical methods and functions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca88654e",
   "metadata": {},
   "source": [
    "1. ```sum()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a = }')\n",
    "print(f'{a.sum() = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97c6f1a8",
   "metadata": {},
   "source": [
    "2. ```mean()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb237ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a.mean() = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b898a48a",
   "metadata": {},
   "source": [
    "3. ```std()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a.std() = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca28d40",
   "metadata": {},
   "source": [
    "4. ```min()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a.min() = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5e2fcdd",
   "metadata": {},
   "source": [
    "5. ```max()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a.max() = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b051c10",
   "metadata": {},
   "source": [
    "**Note:** By default, the above methods use all elements in the array. However, by specifying the axis parameter we can apply an operation along the specified axis. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_axis_arg = np.array([[1, 2], [3, 4]])\n",
    "print(f'{ test_axis_arg.sum(axis=0) = }')  # sum of each column\n",
    "print(f'{ test_axis_arg.sum(axis=1) = }')  # sum of each row"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20f4726e",
   "metadata": {},
   "source": [
    "\n",
    "6. ```np.multiply(a1, a2)```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30658bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.multiply(a, b) = }')\n",
    "print(f'{a * b = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fba2cc60",
   "metadata": {},
   "source": [
    "**Note:** The above is equivalent to ```a*b```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da7e331",
   "metadata": {},
   "source": [
    "7. ```np.divide(a1, a2)```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.divide(b, a) = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3734ecd",
   "metadata": {},
   "source": [
    "**Note:** The above is equivalente to ```b/a```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5820f0c3",
   "metadata": {},
   "source": [
    "8. ```np.absolute(x)```:\n",
    "\n",
    "Take the absolute value (element-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([-1, -2, -100, 5, 7, -23])\n",
    "print(f'{np.absolute(my_array) = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc7a377d",
   "metadata": {},
   "source": [
    "9. ```np.log(x)```:\n",
    "\n",
    "Apply the natural logarithm (element-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{np.log(a) = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce62951e",
   "metadata": {},
   "source": [
    "**Note:** You can find more details and mathematical functions (called universal functions) [here](https://numpy.org/doc/stable/reference/ufuncs.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86802787",
   "metadata": {},
   "source": [
    "### <div id=\"indexing\">1.E Indexing, slicing and iterating</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6603dfa",
   "metadata": {},
   "source": [
    "One-dimensional arrays can be indexed, sliced and iterated over, as with any other Python sequence. Let's see a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(5, 15, 1)\n",
    "print(f'{a = }')\n",
    "print(f'{a[2] = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1464a343",
   "metadata": {},
   "source": [
    "**Note:** As with Python lists, indexing starts at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c282ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a[1:4] = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a63faa5",
   "metadata": {},
   "source": [
    "Let's now iterate over all elements and print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2ce4b97",
   "metadata": {},
   "source": [
    "As mentioned above, multidimensional arrays have one index per axis. To retrieve elements, we need to give indices separated by commans. Let's see a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4], [2, 6, 8, 9], [3, 2, 1, 7]])\n",
    "print(f'{a = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de55e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a[1, 2] = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ed5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a[0:2, 0] = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da59737",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a[:, 0] = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "815eb2c4",
   "metadata": {},
   "source": [
    "**Note:** If we don't provide indexing for a subset of the axes, the last axes are retrieved fully. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd28493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a[2] = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6218e0b5",
   "metadata": {},
   "source": [
    "The above is equivalent to ```print(f'{a[2, :] = }')```.\n",
    "\n",
    "We can also use ```...``` to request full indexing for those axes not specified. Let's imagine we have an array ```my_array``` containing 3 axes, then:\n",
    "\n",
    "```my_array[..., 2]``` is equivalent to ```my_array[:, :, 2]```, and ```my_array[1, ...]``` is equivalent to ```my_array[1, :, :]```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37c27d65",
   "metadata": {},
   "source": [
    "Multidimensional arrays are iterated with respect to the first axis. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec15c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in a:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2bb513f",
   "metadata": {},
   "source": [
    "Nevertheless, if we wish to iterate over each element in a multidimensional array, we can use the ```flat``` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb73c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in a.flat:\n",
    "    print(element)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df43d763",
   "metadata": {},
   "source": [
    "<u>**Boolean indexes:**</u>\n",
    "\n",
    "We can use boolean indexes to explicitely choose which elements from an array we want and which ones we don't. For this, we need to create an array of booleans of the same shape of the array we want to take the data from. For example, let's create an array containing negative and positive values, then let's figure out which of those values are negative and which ones are not by obtaining a boolean array. Then, let's use that boolean array as boolean indexes to extract the negative values from the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde7c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, -1, 1, -2, 8, -3, -10, 32, 14, -18, 54, -79])\n",
    "b = a < 0\n",
    "print(f'{b = }')\n",
    "negative_a = a[b]\n",
    "print(f'{negative_a = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3810bcc",
   "metadata": {},
   "source": [
    "**Note:** Please note that we could simply have done this as well: ```negative_a = a[a < 0]```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "260288be",
   "metadata": {},
   "source": [
    "### <div id=\"shaping\">1.F Changing the shape of an array</div>\n",
    "\n",
    "Let's see a few different ways of changing the shape of an array. Let's first create an array that we will use for all these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4], [2, 6, 8, 9], [3, 2, 1, 7]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38661173",
   "metadata": {},
   "source": [
    "\n",
    "1. ```ravel()``` and ```flatten()```:\n",
    "\n",
    "Both are used to obtained an array collapsed into one dimension.\n",
    "\n",
    "```flatten()``` always returns a copy of the array, while ```ravel()``` returns a view of the original array whenever possible (and original array is not changed). The thing is that if the array returned by ```ravel()``` is modified, then it may modify the elements in the original array (since the view method creates a new array object that looks at the same data!). This will never happen with ```flatten()```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ac82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a.shape = }')\n",
    "flat_a = a.flatten()\n",
    "print(f'{flat_a = }')\n",
    "print(f'{flat_a.shape = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33ed92f1",
   "metadata": {},
   "source": [
    "2. ```reshape()```:\n",
    "\n",
    "Use ```reshape()``` to give a new shape to an array without changing its data (again using the view method). Examples:\n",
    "\n",
    "First, let's reshape the ```a``` array into two axes, the first one having only two indexes, meaning there must be 6 elements in the second axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reshaped_1 = a.reshape(2, 6)\n",
    "print(f'{a_reshaped_1 = }')\n",
    "print(f'{a_reshaped_1.shape = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997aa883",
   "metadata": {},
   "source": [
    "Let's now take the ```a``` array again and reshape into a (6, 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reshaped_2 = a.reshape(6, 2)\n",
    "print(f'{a_reshaped_2 = }')\n",
    "print(f'{a_reshaped_2.shape = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d13b3a10",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- We can omit one of the sizes and use ```-1``` to automatically deduce the corresponding size. For the example above, ```a.reshape(6, -1)``` is equivalent to ```a.reshape(6, 2)```.\n",
    "- We can change the shape of an array in-place with the ```resize()``` function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cd8fa96",
   "metadata": {},
   "source": [
    "3. Transpose an array:\n",
    "\n",
    "Let's create a new array for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd319612",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3], [5, 7, 9]])\n",
    "print(f'{a = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b91bb831",
   "metadata": {},
   "source": [
    "And now, let's transpose it with the ```T``` method (a copy is made):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525eeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{a.T = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "726d4177",
   "metadata": {},
   "source": [
    "### <div id=\"concatenating\">1.G Concatenating, joining and stacking arrays</div>\n",
    "\n",
    "Let's create two arrays to be used in examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5139d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])\n",
    "print(f'{a = }')\n",
    "print(f'{b = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df94550",
   "metadata": {},
   "source": [
    "Let's say we want to add the ```b``` array as an extra element to the array ```a``` along axis 0 (i.e. add it as another row). In that case we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17290f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate((a, b), axis=0)\n",
    "print(f'{c = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28b2ad52",
   "metadata": {},
   "source": [
    "**Note:** We can obtain the same result using the ```np.vstack()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281cfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_prime = np.vstack((a, b))\n",
    "print(f'{c_prime = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7579dba1",
   "metadata": {},
   "source": [
    "Let's say now we want to use the ```b``` array to extend each row in the array ```a``` (i.e. create a new column in the array ```a```). In that case we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42814046",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate((a, b.T), axis=1)\n",
    "print(f'{c = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be2073b5",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "- I needed to transpose the ```b``` array such that both arrays agree on the number of rows.\n",
    "- We can obtain the same using the ```np.hstack()``` function (```np.hstack((a, b.T))```)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40410c39",
   "metadata": {},
   "source": [
    "For more information and examples, you can see [numpy.concatenate](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12ee7823",
   "metadata": {},
   "source": [
    "### <div id=\"adding\">1.H Adding, sorting and removing elements</div>\n",
    "\n",
    "#### 1.H.a Adding\n",
    "\n",
    "There are two methos to add elements to an array:\n",
    "\n",
    "- ```np.insert(arr, obj, values, axis=None)```: Add elements to an specific index where:\n",
    "\n",
    "    - ```arr```: input array\n",
    "    - ```obj```: object that defines the index or indices before which ```values``` is inserted.\n",
    "    - ```values```: values to insert into ```arr```.\n",
    "    - ```axis``` (optional): axis along which to insert ```values```. If axis is ```None``` then ```arr``` is flattened first.\n",
    "    - the output is a copy of ```arr``` with ```values``` inserted (i.e. the insert does not occur in-place and a new array is returned).\n",
    "\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 2, 3, 4, 5, 6])\n",
    "c = np.insert(a, 1, 1)\n",
    "print(f'{c = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "283607d6",
   "metadata": {},
   "source": [
    "You can learn more about the ```insert()``` function in [numpy.insert](https://numpy.org/doc/stable/reference/generated/numpy.insert.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6dfca6b",
   "metadata": {},
   "source": [
    "- ```np.append(arr, values, axis=None)```: Add values to the end of the array.\n",
    "\n",
    "Let's use the ```c``` array again and add ```7``` at the end of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc6c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.append(c, 7)\n",
    "print(f'{c = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35a77b13",
   "metadata": {},
   "source": [
    "You can learn more about the ```append()``` function in [numpy.append](https://numpy.org/doc/stable/reference/generated/numpy.append.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b9337b0",
   "metadata": {},
   "source": [
    "#### 1.H.b Sorting\n",
    "\n",
    "We can use the ```sort(arr, axis=-1, ...)``` function to sort numbers in an array in ascending order, where:\n",
    "\n",
    "- ```arr```: it is the array to be sorted.\n",
    "- ```axis``` (optional): axis along which to sort (int or None). If ```None```, the array is flattened before sorting. The default is -1, which sorts along the last axis.\n",
    "\n",
    "Let's create an array and sort it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845cede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 0, 4, 6, 3, 9, 7])\n",
    "a = np.sort(a)\n",
    "print(f'{a = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4fc4c31",
   "metadata": {},
   "source": [
    "**Note:** If we wish to sort in descending order, we can do the following instead: ```a = np.flip(np.sort(a))```. The ```np.flip()``` function reverses elements of an array along an axis. If you don’t specify the axis, it will reverse the contents along all axes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1836bc92",
   "metadata": {},
   "source": [
    "#### 1.H.c Deleting\n",
    "\n",
    "We can use the ```np.delete(arr, obj, axis=None)``` function to delete elements from an array, where ```obj``` indicates the indices of the elements to remove along the chosen axis. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62993edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 0, 4, 6, 3, 9, 7])\n",
    "a = np.delete(a, [0, 1])\n",
    "print(f'{a = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "274994c5",
   "metadata": {},
   "source": [
    "### <div id=\"random\">1.I Random number generation</div>\n",
    "\n",
    "The possibility of generating random numbers (actually repeatable pseudo-random numbers) is crucial for many applicatoins, for example machine learning.\n",
    "\n",
    "Before we can generate numbers, we need to get an instance of a Generator, which we can do with ```numpy.random.default_rng(seed=None)``` or alternatively in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a83d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "gen = default_rng(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a5da9d9",
   "metadata": {},
   "source": [
    "**Note:** A seed needs to be set to ensure reproducibility (if desired). If a seed is set, the same sequence of numbers will be generated everytime an instance of the generator (using the same seed) is created."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4191f8c7",
   "metadata": {},
   "source": [
    "As an example, let's create an array with shape ```(2, 3)``` filled with floating random numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738166ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gen.random((2, 3))\n",
    "print(f'{a = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f027226",
   "metadata": {},
   "source": [
    "Let's generate now an array of shape ```(2, 3)``` filled with random integer numbers between 0 and 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = gen.integers(10, size=(2, 3))\n",
    "print(f'{a = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf69404c",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "We can specify the start and end of the range used to generate integer values with ```integers()```:\n",
    "\n",
    "```\n",
    "random.Generator.integers(low, high=None, size=None, dtype=np.int64, endpoint=False)\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "- ```low```: Lowest (signed) integers to be drawn from the distribution (unless high=None, in which case this parameter is 0 and this value is used for high).\n",
    "- ```high```: If provided, one above the largest (signed) integer to be drawn from the distribution.\n",
    "\n",
    "```integers()``` returns random integers from ```low``` (inclusive) to ```high``` (exclusive), or if ```endpoint=True```, ```low``` (inclusive) to ```high``` (inclusive)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47020394",
   "metadata": {},
   "source": [
    "Among other things, we can generate numbers from a Normal distribution. For example, let's generate 10000 numbers from a Normal distribution with ```mu=5``` and ```sigma=1```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = gen.normal(5, 1, 10000)\n",
    "print(f'{dist = }') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e4e4cc3",
   "metadata": {},
   "source": [
    "For more information about ```numpy.random``` see [here](https://numpy.org/doc/stable/reference/random/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd4fe4f4",
   "metadata": {},
   "source": [
    "## <div id=\"pandas\">2. Pandas</div>\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a library that enables the manipulation of data in a fast, powerful and easy way. Pandas has two main types of Data Structures*:\n",
    "\n",
    "- ```Series```: 1D labeled array where elements must be of the same data type. Once created, its size cannot be changed.\n",
    "- ```DataFrame```: 2D labeled table where elements can have different data type, and can be removed/added.\n",
    "\n",
    "*Data Structures allow you to organize, process and store data.\n",
    "\n",
    "To install pandas, see [getting_started](https://pandas.pydata.org/getting_started.html) (needs NumPy, among other libraries).\n",
    "\n",
    "You can start using pandas in your codes, by simply adding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3baa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1b0c49f",
   "metadata": {},
   "source": [
    "If the above didn't work, please run the following on a terminal/console:\n",
    "```\n",
    "pip install pandas\n",
    "```\n",
    "or\n",
    "```\n",
    "pip3 install pandas\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395ae2df",
   "metadata": {},
   "source": [
    "### <div id=\"series\">2.A Series</div>\n",
    "\n",
    "Series is a one-dimensional labeled array whose object size cannot be changed.\n",
    "\n",
    "Let's create a Series from an array of integer values which we will label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series(data=[22, 1, 0], index=[\"age\", \"ndogs\",  \"ncats\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a26f8734",
   "metadata": {},
   "source": [
    "The ```index``` parameter accepts a ```list``` that allows you to label the data.\n",
    "\n",
    "The ```data``` argument can take any of the following data types:\n",
    "\n",
    "- ```dict```\n",
    "- ```list```\n",
    "- ```ndarray```\n",
    "\n",
    "Values inside the dictionary and elements in the array can be of ```int```, ```float``` or ```bool``` type.\n",
    "\n",
    "There is also a ```name``` parameter that allows you to name your Series.\n",
    "\n",
    "If ```data``` is of ```dict``` type and ```index``` is not provided, the dictionary keys will be used as index labels.\n",
    "\n",
    "Please see [pandas.Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "779fa916",
   "metadata": {},
   "source": [
    "### <div id=\"dataframes\">2.B DataFrames</div>\n",
    "\n",
    "With Pandas we can take data (from a CSV/TSV file, a SQL database, a dictionary, a NumPy array, etc) and create a Python object with rows and columns called ```DataFrame``` that resembles a table (like one would find in Microsoft Excel, for example).\n",
    "\n",
    "There are many functions for opening different file formats. We will see only how to create a DataFrame out of a CSV file, you can find all other functions [here](https://pandas.pydata.org/docs/reference/io.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89ba04a5",
   "metadata": {},
   "source": [
    "#### <div id=\"csv\">2.B.a Create a DataFrame from a CSV file</div>\n",
    "\n",
    "There are many functions for opening different file formats. We will see only how to create a DataFrame out of a CSV file, you can find all other functions [here](https://pandas.pydata.org/docs/reference/io.html).\n",
    "\n",
    "Let's create a DataFrame out of the ```cost_of_living.csv``` file (from [www.worldata.info](https://www.worlddata.info/cost-of-living.php)) which has a list of countries, each with its ```cost_index```, ```monthly_income``` and ```purchasing_power_index```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c2207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cost_of_living.csv')\n",
    "df.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bcf8ce1",
   "metadata": {},
   "source": [
    "The first line, ```df = pd.read_csv('cost_of_living.csv')``` created the DataFrame, while the second one ```df.head(4)``` printed the first 4 rows. If one would like to print the last ```n``` rows, one would need to use ```df.tail(n)``` instead.\n",
    "\n",
    "**Note:** each entry/row in our DataFrame has an index value. Indexing in DataFrames start at zero. For example, in our DataFrame above, the row corresponding to Switzerland corresponds to the index 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91482ac6",
   "metadata": {},
   "source": [
    "Let's say we wanted only the ```country``` and ```monthly_income``` columns. In that case, we can use the ```usecols``` keyword to pass the list of columns we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_income = pd.read_csv('cost_of_living.csv', usecols = ['country', 'monthly_income'])\n",
    "df_income.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b21c70fa",
   "metadata": {},
   "source": [
    "**Note #1:** if the CSV file doesn't have column names, one can define them with the ```names``` keyword when using the  ```read_csv()``` function.\n",
    "\n",
    "For more options, see [pandas.read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).\n",
    "\n",
    "**Note #2:** If you already created a DataFrame and want to select a subset of columns, you can do something like the following:\n",
    "\n",
    "```\n",
    "new_df = df[[col1, col2]]\n",
    "```\n",
    "\n",
    "```new_df``` will have only ```col1``` and ```col2``` from the ```df``` DataFrame.\n",
    "\n",
    "For example, let's get only the ```country``` column from ```df_income```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad9b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = df_income[['country']]\n",
    "countries_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4097185",
   "metadata": {},
   "source": [
    "Please note that when selecting a single column, one can get a ```DataFrame``` using ```df[['colname']]``` or a ```Series``` using ```df['colname']```. For the example above, let's get now a Series from the ```country``` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268327dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_series = df_income['country']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "857a062c",
   "metadata": {},
   "source": [
    "We can now confirm their types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e993845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{type(countries_series) = }')\n",
    "print(f'{type(countries_df) = }')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23251f31",
   "metadata": {},
   "source": [
    "#### <div id=\"dict\">2.B.b Create a DataFrame from a dictionary</div>\n",
    "\n",
    "One can also create a DataFrame out of a dictionary. In order to convert a certain Python object (dictionary, NumPy array, etc) to a DataFrame, we need to use ```pd.DataFrame()```. For all the options, please see [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\n",
    "    'column1': [1, 2, 3, 4],\n",
    "    'column2': [3, 4, 2, 1],\n",
    "    'column3': [3, 5, 1, 6],\n",
    "}\n",
    "df = pd.DataFrame(my_dict)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7851c1c",
   "metadata": {},
   "source": [
    "Alternatively, one could create a DataFrame from a dictionary of Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0baf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series_dict = {\n",
    "    'column1': pd.Series([1, 2, 3, 4]),\n",
    "    'column2': pd.Series([3, 4, 2, 1]),\n",
    "    'column3': pd.Series([3, 5, 1, 6]),\n",
    "}\n",
    "df = pd.DataFrame(my_dict)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "911ad1f5",
   "metadata": {},
   "source": [
    "One could also create a DataFrame using a list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd2dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'column1': 1, 'column2': 3, 'column3': 3},\n",
    "    {'column1': 2, 'column2': 4, 'column3': 5},\n",
    "    {'column1': 3, 'column2': 2, 'column3': 1},\n",
    "    {'column1': 4, 'column2': 1, 'column3': 6},\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf4a2b3c",
   "metadata": {},
   "source": [
    "#### <div id=\"array\">2.B.c Create a DataFrame from a NumPy array</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ad119",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([[1, 2, 3, 4], [4, 5, 6, 7], [7, 8, 9, 10]])\n",
    "df = pd.DataFrame(array, columns=['a', 'b', 'c', 'd'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df224ab7",
   "metadata": {},
   "source": [
    "Note: The ```columns``` keyword was used to label each column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a9c1c2c",
   "metadata": {},
   "source": [
    "#### <div id=\"summarize\">2.B.d Summarize data</div>\n",
    "\n",
    "Let's read again the ```cost_of_living.csv``` file into a DataFrame and get some statistics/summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cost_of_living.csv')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5af42f00",
   "metadata": {},
   "source": [
    "**<u>Number of rows and columns</u>:**\n",
    "\n",
    "Use ```df.shape``` to get the number of rows (107) and columns (4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dc03f7c",
   "metadata": {},
   "source": [
    "If we only wish to know the number of rows, we can use ```len(df)```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627493cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a6cfc72",
   "metadata": {},
   "source": [
    "**<u>List of column names</u>:**\n",
    "\n",
    "Use ```df.columns``` to get the list of column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d57238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93244bfd",
   "metadata": {},
   "source": [
    "**<u>Statistics for numerical columns</u>**\n",
    "\n",
    "Another very useful command is ```df.describe()``` which provides summary statistics for numerical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fa04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "976b6502",
   "metadata": {},
   "source": [
    "There are many other methods that can be used to get statistics from a DataFrame (a Series or a column). Here is some of them:\n",
    "\n",
    "- ```df.sum()```: returns the sum of each column\n",
    "- ```df.mean()```: returns the mean of each column\n",
    "- ```df.median()```: returns the mediam of each column\n",
    "- ```df.std()```: returns the standard deviation of each column\n",
    "- ```df.corr()```: returns the correlation between columns in a data frame\n",
    "- ```df.count()```: returns the number of non-null values in each column\n",
    "- ```df.min()```: returns the lowest value in each column\n",
    "- ```df.max()```: returns the highest value in each column\n",
    "\n",
    "You can find other functions in [api-dataframe-stats](https://pandas.pydata.org/pandas-docs/version/0.20.2/api.html#api-dataframe-stats)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c19d181a",
   "metadata": {},
   "source": [
    "**<u>Value counts</u>:**\n",
    "\n",
    "The ```value_counts()``` function can be used to count the number of occurrences. For example, let's open the ```users.csv``` file which for a few different 'users', their age and country were recorded. Let's use the ```value_counts()``` function to count the number of times each age appears:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('users.csv')\n",
    "users['age'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a85baa85",
   "metadata": {},
   "source": [
    "As you can see, the most common ages are 19 and 32, both appearing 3 times."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "406fbb6b",
   "metadata": {},
   "source": [
    "#### <div id=\"combine\">2.B.e Combining and merging DataFrames</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f87e354",
   "metadata": {},
   "source": [
    "**<u>Concatenating DataFrames</u>:**\n",
    "\n",
    "The ```concat()``` function can be used to concatenate DataFrames. Use the following syntax to add rows from DataFrames ```df1``` and ```df2``` to a new DataFrame (the same columns should be available in both DataFrames):\n",
    "\n",
    "```\n",
    "pd.concat([df1, df2], ignore_index=True)\n",
    "```\n",
    "\n",
    "```ignore_index=True``` will reset the indexing to force unique indexes.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a4226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1 = {'A': [1, 2], 'B': [1, 3]}\n",
    "dict_2 = {'A': [5, 8], 'B': [2, 9]}\n",
    "df1 = pd.DataFrame(dict_1)\n",
    "df2 = pd.DataFrame(dict_2)\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "157239ff",
   "metadata": {},
   "source": [
    "Use the following syntax to add columns from DataFrames to a new DataFrame (input DataFrames should have the same number of rows and indexing):\n",
    "\n",
    "```\n",
    "pd.concat([df1, df2], axis=1)\n",
    "```\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_1 = {'A': [1, 2], 'B': [1, 3]}\n",
    "dict_2 = {'C': [5, 8], 'D': [2, 9]}\n",
    "df1 = pd.DataFrame(dict_1)\n",
    "df2 = pd.DataFrame(dict_2)\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e4ebb38",
   "metadata": {},
   "source": [
    "**<u>Merging DataFrames:</u>**\n",
    "\n",
    "Let's say we have two DataFrames with different (suplementary) information about the same countries. Let's mimic that by creating another DataFrame with the ```cost_index``` and ```purchasing_power_index``` columns from the ```cost_of_living.csv``` file and merge it with ```df_income``` that we created before (which contains only the ```country``` and ```monthly_income``` columns). Here we will use the ```pd.merge()``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rest = pd.read_csv('cost_of_living.csv', usecols = ['country', 'cost_index', 'purchasing_power_index'])\n",
    "df_rest.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.merge(df_income, df_rest, how='left')\n",
    "df_full.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3933bf4c",
   "metadata": {},
   "source": [
    "Note: ```how=left``` is used only to be able to compare with the ```join()``` function (see below). To learn about ```how``` and other attributes, see [pandas.DataFrame.merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html).\n",
    "\n",
    "As you can see, ```df_full``` has exactly the same information as the DataFrame that we created using all columns (with just a slightly different order for the columns). We can change the order of the columns in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[['country', 'cost_index', 'monthly_income', 'purchasing_power_index']]\n",
    "df_full.head(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5552b68b",
   "metadata": {},
   "source": [
    "\n",
    "Alternatively, we can use the ```join()``` function to add columns from two DataFrames sharing a column. ```join()``` can be used to join columns with another DataFrame either on index or on a key column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0644d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_income.join(df_rest.set_index('country'), on='country')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ab18d80",
   "metadata": {},
   "source": [
    "As you can see, we obtained the same result as with the ```merge()``` function. For more details about the ```join()``` function, see [pandas.DataFrame.join](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54c54e73",
   "metadata": {},
   "source": [
    "#### <div id=\"write\">2.B.f Save DataFrame to a file and convert to NumPy arrays</div>\n",
    "\n",
    "DataFrames can be saved into different types of files (CSV, Excel, JSON, SQL table, etc). They are of the form ```df.to_filetype(filename)```. To find all of them, please see [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\n",
    "\n",
    "It is also possible to convert a DataFrame to a NumPy ```ndarray``` by using the ```to_numpy()``` function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7cb32b1",
   "metadata": {},
   "source": [
    "#### <div id=\"clean\">2.B.g Handling missing data</div>\n",
    "\n",
    "More often than not, some information is partially missing in our input data. Let's create a DataFrame from a dictionary that has some missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5919a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'name': ['John', 'Maria', 'Jennifer', 'Matthias', 'Matt'],\n",
    "    'age': [23, 32, 45, 52, 39],\n",
    "    'nationality': ['England', 'Argentina', 'USA', None, 'Canada'],\n",
    "    'civil_status': ['married', None, 'single', 'divorced', 'single'],\n",
    "    'stars': [2, 3, 4, 5, None],\n",
    "}\n",
    "data_rankings = pd.DataFrame(data_dict)\n",
    "data_rankings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c8e0fd4",
   "metadata": {},
   "source": [
    "As you can see, missing/null information is denoted by ```NaN```.\n",
    "\n",
    "\n",
    "We can check for missing values with the ```isnull()``` function. This will return ```True``` for a missing value and ```False``` for non-missing values, as you can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rankings.isnull()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7f7b5f4",
   "metadata": {},
   "source": [
    "We can count how many missing values per column are present in the DataFrame in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rankings.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd6a44ee",
   "metadata": {},
   "source": [
    "Note: Alternatively, if we want to identify all non-missing values, we can use ```notnull()``` instead."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01d5c505",
   "metadata": {},
   "source": [
    "Now, you can decide to remove rows with a missing value using ```dropna()```, remove columns with missing values with ```dropna(axis=0)``` or fill the missing values with other values using ```fillna(x)``` which fills the missing values with ```x```. ```x``` can be anything, for example it could be ```df.mean()``` (you can use pretty much any stat function).\n",
    "\n",
    "For our example above, let's replace missing information for the columns ```'age'``` and ```'stars'``` by their averages. Then, let's remove rows for which there is still missing data (effectively removing rows with missing data in columns ```'name'```, ```'nationality'``` and ```'civil_status'```.)\n",
    "\n",
    "Let's first replace all missing values for columns ```'age'``` and ```'stars'``` by their averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd788df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a dictionary collecting the average for each desired column\n",
    "values = {key: data_rankings[key].mean().astype(int) for key in ['age', 'stars']}\n",
    "\n",
    "# Let's then fill missing values\n",
    "df = data_rankings.fillna(value=values)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6efa5224",
   "metadata": {},
   "source": [
    "Let's now remove any row still having missing info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52446fcf",
   "metadata": {},
   "source": [
    "Note: If one wishes to drop rows with missing info only on specific columns, we can use the ```subset``` argument, for example:\n",
    "\n",
    "```\n",
    "df = df.dropna(subset=['name', 'nationality'])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c2fcfbb",
   "metadata": {},
   "source": [
    "#### <div id=\"transform\">2.B.h Transform and replace data</div>\n",
    "\n",
    "**<u>The ```replace()``` function</u>:**\n",
    "\n",
    "If you need to replace certain values by always the same set of values, you can use the ```replace()``` function. Here are two examples:\n",
    "\n",
    "i. Let's change all zeros by ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e49205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'name': ['John', 'Maria', 'Jennifer', 'Matthias', 'Matt'],\n",
    "    'stars': [0, 2, 4, 3, 5],\n",
    "}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(0, 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "577487c0",
   "metadata": {},
   "source": [
    "Here I used ```inplace=True``` to replace values directly on the DataFrame, instead of having to make a new copy of the DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88aa8200",
   "metadata": {},
   "source": [
    "ii. Let's now replace several values at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'name': ['John', 'Maria', 'Jennifer', 'Matthias', 'Matt'],\n",
    "    'stars': ['one', 'two', 'three', 'four', 'five'],\n",
    "}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbbfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(['one', 'two', 'three', 'four', 'five'], [1, 2, 3, 4, 5], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "724a786d",
   "metadata": {},
   "source": [
    "Tip: if you need to rename column names, you could do the following:\n",
    "\n",
    "```\n",
    "df.rename(columns={'old_name_1': 'new_name_1', 'old_name_2': 'new_name_2'}, inplace=True)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5462c937",
   "metadata": {},
   "source": [
    "**<u>Replace values depending on a condition with the ```where()``` function from NumPy</u>:**\n",
    "\n",
    "The syntax is the following:\n",
    "\n",
    "```\n",
    "where(condition, then, else)\n",
    "```\n",
    "\n",
    "Let's once again use the ```data_rankings``` DataFrame and convert the age values to the following two ranges: ```'0-45'``` and ```'45+'```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254af6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "df = copy.deepcopy(data_rankings)\n",
    "df['age'] = np.where(data_rankings['age'] > 45, '45+', '0-45')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97c8bda0",
   "metadata": {},
   "source": [
    "As you can see, Matthias was assigned to the ```'45+'``` group since he is 52 years old, while the rest to the ```'0-45'``` group.\n",
    "\n",
    "Note: I made a copy of the ```data_rankings``` DataFrame to preserve it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4067777",
   "metadata": {},
   "source": [
    "**<u>Replace values using the ```applymap()``` function</u>:**\n",
    "\n",
    "Sometimes, it is needed to apply a custom function to each value/element in a DataFrame. For such cases, the ```applymap()``` function can be used and it works similarly to the Python built-in ```map()``` function, i.e. a function is applied to all elements in the DataFrame. Let's take a look at the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a76893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'distance_1 (m)': [10325, 45212, 829252, 87328],\n",
    "    'distance_2 (m)': [76290, 621852, 42196, 980171],\n",
    "}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fdb6423",
   "metadata": {},
   "source": [
    "Imagine that all values correspond to meters but we wish to convert them to kilometers. In that case, we could do the following, where we define a function (```m_to_km()```) to convert meters to kilometers, give it as input to the ```applymap()``` function, and then rename the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d09ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_to_km (value):\n",
    "    return value * 0.001\n",
    "\n",
    "df = df.applymap(m_to_km)\n",
    "df.rename(columns={'distance_1 (m)': 'distance_1 (km)', 'distance_2 (m)': 'distance_2 (km)'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e2a6b54",
   "metadata": {},
   "source": [
    "#### <div id=\"remove\">2.B.i Remove unwanted rows/columns</div>\n",
    "\n",
    "You can use the ```drop()``` function to remove unwanted columns or rows from a DataFrame:\n",
    "\n",
    "```df.drop(to_drop, inplace=True, axis=1)```\n",
    "\n",
    "Let's recycle one of the examples above (```data_rankings```) and remove the second row and reset the indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd786cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "df.drop(2, inplace=True)\n",
    "df.reset_index(inplace=True)  # force to reset indexing, so there are no missing indexes\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cd98ec8",
   "metadata": {},
   "source": [
    "**Note:** We could have done the following as well: ```df.drop(df.index[2], inplace=True)```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "849fc169",
   "metadata": {},
   "source": [
    "Let's now remove the ```'civil_status'``` column from the ```data_rankings``` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc641f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.deepcopy(data_rankings)\n",
    "df.drop(['civil_status'], inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ec19030",
   "metadata": {},
   "source": [
    "Alternatively, we could do the following as well: ```df.drop(columns=['civil_status'], inplace=True)``` or make a copy of the DataFrame selecting only the desired columns: ```new_df = df[['name', 'age', 'nationality', 'stars']]```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3316c8f8",
   "metadata": {},
   "source": [
    "#### <div id=\"query\">2.B.j Examine the data and make selections and queries</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae40a9eb",
   "metadata": {},
   "source": [
    "**<u>Sort data</u>:**\n",
    "\n",
    "Rows can be ordered based on columns content.\n",
    "\n",
    "- ```df.sort_values(column_1)``` sorts the ```df``` DataFrame in ascending order based on the values in the ```column_1``` column.\n",
    "- ```df.sort_values(column_1, ascending=False)``` sorts the ```df``` DataFrame in descending order based on the values in the ```column_1``` column.\n",
    "- ```df.sort_values([column_1, column_2], ascending=[True, False])``` sorts the values by ```column_1``` in ascending order, then sorts the values by ```column_2``` in descending order."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7d401fe",
   "metadata": {},
   "source": [
    "**<u>Select rows by index or label</u>:**\n",
    "\n",
    "There are two ways of accessing the data from specific rows, by label- or position-based indexing. In the former, we pick rows matching given labels in the index axis of the DataFrame using ```loc[]```, while in the later we access rows based on their position in the DataFrame using ```iloc[]```. Let's take a look at the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cost_of_living.csv')\n",
    "countries_indexing = df.set_index('country')  # this is to use the country column as indexes\n",
    "countries_indexing = countries_indexing.rename_axis(None)  # not necessary, it is just easier to highlight that the first column is the index axis (by removing its name)\n",
    "countries_indexing.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7f65221",
   "metadata": {},
   "source": [
    "I created again a DataFrame out of the ```'cost_of_living.csv'``` file and instead of having numerical index values, I used the ```'country'``` column as indexes (since it has unique values). Now, we can use the ```loc[]``` to obtain a DataFrame only for Switzerland and Iceland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_indexing.loc[['Switzerland', 'Iceland']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35e53ec5",
   "metadata": {},
   "source": [
    "Now, we can get the same rows by using their numerical positions (1 and 4, respectively) using ```iloc[[1, 4]]```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_indexing.iloc[[1, 4]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a839bcd9",
   "metadata": {},
   "source": [
    "Please note that we could also have done the following to get the same rows (since the labels in ```df``` match their positions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[1, 4]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "863428ef",
   "metadata": {},
   "source": [
    "**<u>Selecting rows satisfying a condition</u>:**\n",
    "\n",
    "In DataFrames, we can easily select data satisfying certain requirements. Let's re-use again the ```data_rankings``` DataFrame and get a new DataFrame listing people that have 3 or more stars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c322080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_rankings[data_rankings['stars'] > 2]\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c28caad0",
   "metadata": {},
   "source": [
    "**Note:** By doing ```data_rankings[condition]```, I obtain a subset of the ```data_rankings``` DataFrame that satisfy the ```condition```, in this case, the codition is ```data_rankings['stars'] > 2``` which only selects rows in which the value for the column ```stars``` is greater than 2. This is known as filtering. The condition could be composed using ```&``` (AND) or ```|``` (OR), for example: ```(data_rankings['stars'] > 2) & (data_rankings['age'] > 40)```. In this case I ask starts to be greater than 2 and age to be greater than 40.\n",
    "\n",
    "Let's get now the age of all the people that have 3 or more stars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = df['age'].to_numpy()\n",
    "print(f'Age of people with stars > 2: {people}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "530adea6",
   "metadata": {},
   "source": [
    "Note: I have used the ```to_numpy()``` function to get an ```ndarray```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbbd1e7f",
   "metadata": {},
   "source": [
    "Another way to select rows satisfying a given condition is to use the ```query(condition)``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e19dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = data_rankings.query('stars > 2')['age'].to_numpy()\n",
    "print(f'Age of people with stars > 2: {people}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc7d285e",
   "metadata": {},
   "source": [
    "**<u>Grouping data</u>:**\n",
    "\n",
    "What about if we wish to extract some information after grouping our data into categories? Let's go through two examples using the ```Walmart.csv``` file from [www.kaggle.com](https://www.kaggle.com/datasets/naveenkumar20bps1137/walmart-sales-analysis) which lists some of their received orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('Walmart.csv')\n",
    "orders.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3083d8a1",
   "metadata": {},
   "source": [
    "\n",
    "We can see therein some information, like the category assigned to each order as well how much it was spent on each order (```Sales```).\n",
    "\n",
    "**i. Obtain the total of ```Sales``` for each category:**\n",
    "\n",
    "For this, we need to use the ```groupby()``` function, then take the ```Sales``` column and sum all its values for each category, and finally sort them to show the highest values first. We can do all this with a single line, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda3b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = orders.groupby('Category')['Sales'].sum().to_frame().sort_values(by='Sales', ascending=False)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d55d6517",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- ```orders.groupby('Category')``` returns a groupby object, not a DataFrame.\n",
    "- We get a Series after using ```sum()```, which is converted to a DataFrame with the ```to_frame()``` function.\n",
    "\n",
    "It is also possible to group based on values from multiple columns. For example, let's now get the total sales for each category for every city:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3239d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = orders.groupby(['Category', 'City'])['Sales'].sum().to_frame().sort_values(by='Sales', ascending=False)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e67c9389",
   "metadata": {},
   "source": [
    "From this we know that the city with the best selling category is Los Angeles, where phones worth 29503.04 were sold."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6305f1d6",
   "metadata": {},
   "source": [
    "**i. Obtain further sales statistics on every category:**\n",
    "\n",
    "Let's now get the number of orders, the average sales and the total sales for every category. We will again use the ```groupby()``` function but this time together with the ```agg()``` function, to aggregate statistics on every category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = orders.groupby('Category').agg({'Sales': [np.size, np.mean, np.sum]}).sort_values(by=('Sales', 'sum'), ascending=False)\n",
    "data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62863b5b",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- ```agg({'Sales': [np.size, np.mean, np.sum]})``` aggregates three operations (```np.size```, ```np.mean``` and ```np.sum```) over the ```Sales``` column.\n",
    "- ```sort_values(by=('Sales', 'sum'), ascending=False)``` is used to order rows based on the total sales and showing first the highest values (i.e. descending order).\n",
    "\n",
    "**Tip:** If you need to retrieve any of the aggregated columns, let's say for example the ```size``` column, then do the following: ```data['Sales']['size']```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fb49ac8",
   "metadata": {},
   "source": [
    "#### <div id=\"add\">2.B.k Add new columns/rows</div>\n",
    "\n",
    "**<u>Add a new column</u>:**\n",
    "\n",
    "First, let's create a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5365a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'A': [0, 1, 2, 3, 4],\n",
    "    'B': [1, 2, 3, 4, 5],\n",
    "    'C': [3, 1, 5, 6, 8],\n",
    "    'D': [9, 7, 1, 3, 5],\n",
    "}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d211212d",
   "metadata": {},
   "source": [
    "Let's create now a new ```'D'``` column which would be the sum of all other columns. We will see two ways of doing this:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aed62b9e",
   "metadata": {},
   "source": [
    "i. Sum of Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['E'] = df['A'] + df['B'] + df['C'] + df['D']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5045935",
   "metadata": {},
   "source": [
    "ii. Using the ```apply()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sum(values):\n",
    "    return values.sum()\n",
    "\n",
    "df = pd.DataFrame(data_dict)\n",
    "df['E'] = df.apply(my_sum, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "090dfc4b",
   "metadata": {},
   "source": [
    "Note: we could also have used a lambda function with the ```apply()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e012ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "df['E'] = df.apply(lambda x:x.sum(), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f23dad3b",
   "metadata": {},
   "source": [
    "Let's now see another example where we add a new column as a result of a condition applied to a given column. In this case, we add a new column ```E``` that is ```True``` if ```A``` is greater than 2 and ```False``` otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "df['E'] = df['A'] > 2\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "832b8153",
   "metadata": {},
   "source": [
    "Alternatively, we could have used the ```where()``` function from NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "df['E'] = np.where(df['A'] > 2, True, False)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1d43dd5",
   "metadata": {},
   "source": [
    "Let's see another example in which we add a new column to a DataFrame, but now using the ```insert()``` function, which is used to add a column to a given index in the column axis.\n",
    "\n",
    "We will use again our ```data_rankings``` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rankings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6656588",
   "metadata": {},
   "source": [
    "And we will group people into age groups. We will use the ```cut()``` function which can be used to segment data into bins (i.e. place data into discrete intervals, known as bins):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 15, 25, 35, 45, 65, 100]\n",
    "data_rankings.insert(2, 'age-group', pd.cut(data_rankings['age'], bins))\n",
    "data_rankings.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de6f4e37",
   "metadata": {},
   "source": [
    "**<u>Add a new row</u>:**\n",
    "\n",
    "Let's create again a new DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78b8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_dict)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f845de83",
   "metadata": {},
   "source": [
    "Let's now add a new row using ```loc[]```, which for each column we will be the sum of all other rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1caeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[5] = df.apply(lambda x:x.sum(), axis=0)\n",
    "df.head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3cd4ac0",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- I could have done the following as well: ```df.loc[5] = df.loc[0] + df.loc[1] + df.loc[2] + df.loc[3] + df.loc[4]```\n",
    "- ```df.iloc[5]``` wouldn't work since there is no row at index 5, this can only be used to replace/update an existing row."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7cab13d",
   "metadata": {},
   "source": [
    "#### <div id=\"plotting\">2.B.l Plotting</div>\n",
    "\n",
    "In this section, we will create some graphical representations:\n",
    "\n",
    "**<u>Vertical bar plot</u>:**\n",
    "\n",
    "Let's recycle our ```data_rankings``` DataFrame and make a vertical bar plot using the number of counts for each age group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3890f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rankings['age-group'].value_counts().plot.bar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ca3bcd9",
   "metadata": {},
   "source": [
    "**Note:** ```data_rankings['age-group'].value_counts().plot(kind='bar')``` would also work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd76481d",
   "metadata": {},
   "source": [
    "**<u>Scatter plot</u>:**\n",
    "\n",
    "Let's go back to our DataFrame using the ```cost_of_living.csv``` file. Let's say we wish to determine if there is any trend or correlation between ```purchasing_power_index``` and ```monthly_income```, in that case, we could want to look at a scatter plot like the following one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d27f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cost_of_living.csv')\n",
    "df.plot.scatter(x='monthly_income', y='purchasing_power_index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d13f1b2f",
   "metadata": {},
   "source": [
    "**Note:** ```df.plot(x='monthly_income', y='purchasing_power_index', kind='scatter')``` would also make the trick."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7fc198",
   "metadata": {},
   "source": [
    "**<u>Histogram</u>:**\n",
    "\n",
    "Let's now make a histogram using the ```monthly_income``` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf966f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['monthly_income'].plot(kind='hist')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fce7a936",
   "metadata": {},
   "source": [
    "For other plotting options, see [pandas.DataFrame.plot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a14f733c",
   "metadata": {},
   "source": [
    "#### <div id=\"other\">2.B.m Other helpful attributes and functions</div>\n",
    "\n",
    "**<u>```is_unique``` and ```set_index()```:</u>**\n",
    "\n",
    "Sometimes, we expect a certain column to have unique values. We can confirm if that is correct in our DataFrame using the ```is_unique``` attribute.\n",
    "\n",
    "Let's take a look at an example where a DataFrame has an ```'id'``` column with non-unique values and let's look at the result given by the ```is_unique``` attibute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16329623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[0], [1], [2], [2], [4], [5]]), columns=['id'])\n",
    "df['id'].is_unique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "804d096a",
   "metadata": {},
   "source": [
    "As expected, ```is_unique``` returned ```False``` since ```2``` is repeated.\n",
    "\n",
    "Let's now look at an example where all values are unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930960af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[0], [1], [2], [3], [4], [5]]), columns=['id'])\n",
    "df['id'].is_unique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5a93ec2",
   "metadata": {},
   "source": [
    "Now as expected, ```is_unique``` returned ```True```. If we wish, since the ```'id'``` column has unique values, we could set it as index in our DataFrame with the ```set_index()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8dd891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a38458b0",
   "metadata": {},
   "source": [
    "**<u>Pivotting your DataFrame</u>:**\n",
    "\n",
    "Let's create a tiny DataFrame with prices from four different stores for two products (a TV and a smartphone):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ca3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.DataFrame({\n",
    "    'product': ['TV', 'TV', 'TV', 'TV', 'Smartphone', 'Smartphone', 'Smartphone', 'Smartphone'],\n",
    "    'store': ['Fnac', 'Fust', 'Interdiscount', 'Amazon', 'Fust', 'Fnac', 'Amazon', 'Interdiscount'],\n",
    "    'price':[499.99, 498.05, 460.20, 451.90, 259.99, 260.05, 250.20, 258.39],\n",
    "})\n",
    "products.head(8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bf3c69c",
   "metadata": {},
   "source": [
    "Let's say we wish to more easily compare prices for the same products on different stores, if that's so, we could do something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb36f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_products = products.pivot(index='product', columns='store')\n",
    "print(pivot_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74004e93",
   "metadata": {},
   "source": [
    "That's all for now. If you wish to learn about data visualization in Python, take a look at the next module / notebook (#5)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
